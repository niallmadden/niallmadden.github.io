{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Modules-for-this-notebook\" data-toc-modified-id=\"Modules-for-this-notebook-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Modules for this notebook</a></span></li></ul></li><li><span><a href=\"#Computing-Degree-Centrality\" data-toc-modified-id=\"Computing-Degree-Centrality-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Computing Degree Centrality</a></span><ul class=\"toc-item\"><li><span><a href=\"#Computing-it-in-netwprkx\" data-toc-modified-id=\"Computing-it-in-netwprkx-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Computing it in <code>netwprkx</code></a></span></li></ul></li><li><span><a href=\"#Eigenvector-Centrality\" data-toc-modified-id=\"Eigenvector-Centrality-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Eigenvector Centrality</a></span><ul class=\"toc-item\"><li><span><a href=\"#Computing-Eigenvalues-with-eigh\" data-toc-modified-id=\"Computing-Eigenvalues-with-eigh-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Computing Eigenvalues with <code>eigh</code></a></span></li><li><span><a href=\"#The-Power-Method\" data-toc-modified-id=\"The-Power-Method-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>The Power Method</a></span></li><li><span><a href=\"#Computing-it-in-networkx\" data-toc-modified-id=\"Computing-it-in-networkx-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Computing it in <code>networkx</code></a></span></li></ul></li><li><span><a href=\"#Closeness-Centrality\" data-toc-modified-id=\"Closeness-Centrality-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Closeness Centrality</a></span></li><li><span><a href=\"#Betweenness-Centrality\" data-toc-modified-id=\"Betweenness-Centrality-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Betweenness Centrality</a></span></li><li><span><a href=\"#Example:-15th-century-Florentine-marriages\" data-toc-modified-id=\"Example:-15th-century-Florentine-marriages-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Example: 15th-century Florentine marriages</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-example\" data-toc-modified-id=\"The-example-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>The example</a></span></li><li><span><a href=\"#Compute-centralities\" data-toc-modified-id=\"Compute-centralities-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Compute centralities</a></span></li><li><span><a href=\"#Drawing-graphs-based-on-centrality\" data-toc-modified-id=\"Drawing-graphs-based-on-centrality-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Drawing graphs based on centrality</a></span></li></ul></li><li><span><a href=\"#Code-corner-(not-covered-in-class-explicitly)\" data-toc-modified-id=\"Code-corner-(not-covered-in-class-explicitly)-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Code corner (not covered in class explicitly)</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>CS4423-Networks: Week 7 (26+27 Feb 2025) \n",
    "\n",
    "# Part 2: Computing Centrality Measures\n",
    "Niall Madden, \n",
    "School of Mathematical and Statistical Sciences  \n",
    "University of Galway\n",
    "\n",
    "\n",
    "This Jupyter notebook, and PDF and HTML versions, can be found at https://www.niallmadden.ie/2425-CS4423/#Week07\n",
    "\n",
    "<div class=\"rc\"><font size=\"-1\"><em>This notebook was written by Niall Madden, adapted from notebooks by Angela Carnevale.</em></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Modules for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "opts = { \"with_labels\": True,  \"node_color\": \"gold\"} # gold nodes today\n",
    "\n",
    "np.set_printoptions(precision=3)    # just display arrays to 3 decimal places\n",
    "np.set_printoptions(suppress=True)  # avoid scientific notation (better for matrices)\n",
    "\n",
    "from queue import Queue # Use this in computing distances\n",
    "import yaml    # for saving and diplaying data, especially dictionaries\n",
    "import pandas as pd  # summarising data\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computing Degree Centrality\n",
    "\n",
    "Computing the *Degree Centrality* of a graph is easy, and there are many ways to do it. Here we'll look at one way involving the adjancy matrix, since the core idea will be used again for Closeness Centraility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We'll start with an example: where $deg(5)=4$, $deg(4)=3$ and $deg(3)=2$.  \n",
    "\n",
    "As an extra trick, we'll force `networkx` to order the nodes lexigraphically, by\n",
    "* Creating an empty graph\n",
    "* adding the nodes first (in the order I want)\n",
    "* then add the edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = nx.Graph()                # empty graph\n",
    "G1.add_nodes_from(range(6))    # add nodes 0,1,2,3,4,5 in that oder\n",
    "EdgeList = [[5,0],[5,1],[5,2],[5,3],[4,3],[4,2],[4,1]]\n",
    "G1.add_edges_from(EdgeList) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "nx.draw(G1,**opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Compute the adjacency matrix, $A_1$ (as as numpy array), and then multiply by a vector of ones, thus computing the row sums of $A_1$. Then we normalise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = nx.adjacency_matrix(G1).toarray();\n",
    "n = G1.order()\n",
    "e = np.ones((n,1))    # vector of ones\n",
    "n = G1.order()\n",
    "degree_vector = A1@e/(n-1)   # normalised \n",
    "for i in range(6):\n",
    "    print(f\"Node {i} has degree {degree_vector[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Computing it in `netwprkx`\n",
    "\n",
    "Though it is hardly needed, one can compute the degree cenrality of this network  using the `nx.degree_centrality()` method. Note that this returns a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CD = nx.degree_centrality(G1)\n",
    "print(CD)\n",
    "print(f\"\\nThe degree centrality of Node 3 is {CD[3]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Eigenvector Centrality\n",
    "\n",
    "To compute the Eigenvector Centrality of nodes in  network, $G$:\n",
    "* Compute the adjacency matrix, $A$.\n",
    "* Compute the largest, positive eigenvalue of $A$ (since $A$ is symmetric, this is unique)\n",
    "* It has a corresponding positive eigenvector,  $\\vec v$, which we can scale so that $v^v=1$.\n",
    "* $v_i$ is the Eigenvector Centrality node $i$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Computing Eigenvalues with `eigh`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We can use `np.linalg.eig()` which computes the eigenvalues and eigenvectors of a matrix:\\\n",
    "`l, V = np.linalg.eig(A)`\n",
    "computes \n",
    "* `l` : an array of length $n$ containing the eigenvalues of $A$. (Note: we can't call this array `lambda`, since that is a keyword in Python.\n",
    "* `V`: a $n \\times n$ matrix; column $i$ of $V$ is the eigenvector corresponding to the eigenvalues $\\lambda_i$.\n",
    "\n",
    "(Note: since $A$ s symmetric, it can be faster to use the `np.linalg.eigh()` function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "l, V = np.linalg.eig(A1)\n",
    "print(f\"The eigenvalues of A are {l}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is an eigenvalue listed which is positive, amd larger than the rest. Let's look at the corresponding eigenvector. We make have to scale by $-1$, if the enties are negative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_max = np.argmax(l)    # get index of largest eigenvalue\n",
    "v = V[:,i_max]*np.sign(V[0,i_max])   # set v to be corresponding e'vec; ensure it is positive\n",
    "print(\"v=\",v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    print(f\"Node {i} has eigenvector centrality {v[i]:7.4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Power Method\n",
    "\n",
    "There are subfields in the *Numerical Linerar Algebra* dedicated to computing estimates for eigenvalues and eigenvectors. When we only need one eigenvalue, and it is the largest,    use the **[Power method](https://en.wikipedia.org/wiki/Power_iteration)**:\n",
    "\n",
    "1. start with any $u = (1, 1, \\dots, 1)$, say;\n",
    "\n",
    "2. keep replacing $u \\gets Au$ until $u/\\|u\\|$ becomes stable ...\n",
    "\n",
    "**Questions** Does this work? Meaning:\n",
    "* Does the sequence actually converge?\n",
    "* Does it return the correct values?\n",
    "\n",
    "We won't study the theory of that - but will check an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here is an implementation. We'll just do 10 iterations. By rights, we should use a while loop to iterate until successive estimates are sufficiently close to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "n = G1.order()\n",
    "u = np.ones((n,1)); u=u/np.linalg.norm(u)\n",
    "for i in range(10):   \n",
    "    v = A1 @ u  # update u\n",
    "    l = v[0]/u[0] # appriximate the eigenvalue\n",
    "    u = v/np.linalg.norm(v) # normalise it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result we get is as follows (compare yourself with the value computed earlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Computing it in `networkx`\n",
    "\n",
    "To compute eigenvector centraility in `networkx`, we can use the `nx.eigenvector_centrality` function, which returns a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CE = nx.eigenvector_centrality(G1)\n",
    "print(yaml.dump(CE))  # looks better than \"print(CV)\"\n",
    "\n",
    "print(f\"\\nThe Eigenvector  centrality of Node 3 is {CE[3]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Closeness Centrality\n",
    "\n",
    "We learned yesterday that the **normalised closeness centrality** of node $i$ is\n",
    "$$\n",
    "C_i^C =  \\frac{n-1}{\\sum_{j=1}^n d_{ij}}.\n",
    "$$\n",
    "\n",
    "To compute this, for all nodes, we could construct the *distance matrix* for the graph. For that, we need to compute the distance between every pair of nodes. As we learned last week. that can be done with *BFS*. We learned how to do that in Week 6 (Part 1). Here is a different implementation..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* The following `python` function implements\n",
    "BFS for shortest distance from a previous lecture.  \n",
    "* It takes a graph $G = (X, E)$ and a vertex $x \\in X$\n",
    "as its arguments. \n",
    "* It returns a **dictionary**, which assigns to each node its distance to $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances(G, x): \n",
    "    # 1. init: set up the dictionary and a queue\n",
    "    dists = { y: None for y in G } # distances\n",
    "    Q = Queue() # queue of nodes to be visited\n",
    "    dists[x] = 0\n",
    "    Q.put(x)\n",
    "    \n",
    "    # 2. loop\n",
    "    while not Q.empty(): \n",
    "        y = Q.get() \n",
    "        for z in G.neighbors(y):\n",
    "            if dists[z] is None:\n",
    "                dists[z] = dists[y] + 1\n",
    "                Q.put(z)\n",
    "    \n",
    "    # 3. stop here\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's check it works for Node 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances(G1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use these values to build the *distance matrix*, $D_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D1 = np.zeros_like(A1)\n",
    "for i in range(n):\n",
    "    d_i =  distances(G1,i)\n",
    "    D1[i,:]=list(d_i.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(D1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now compute the *distance sum* vector, $\\vec s$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=G1.order()\n",
    "s = D1 @ np.ones((n,1))\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, compute the Closeness Centrality vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CC = (n-1)/s   # note: using entrywise division\n",
    "print(CC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Compare with the `networkx` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.closeness_centrality(G1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Betweenness Centrality\n",
    "\n",
    "From yesterday: the **betweenness centrality**, $c_i^B$ of node $i$  is defined as\n",
    "$$\n",
    "  c_i^B = \\sum_{j} \\sum_{k} \\frac{n_i(j,k)}{n(j,k)}, \\qquad  {j \\neq k \\neq i}\n",
    "$$\n",
    "where\n",
    "* $n(j,k)$ denotes the _number_  of shortest paths from  node $j$ to node $k$, and \n",
    "* $n_i(j,k)$ denotes the  number of those shortest paths \\emph{passing through} node $i$.\n",
    "\n",
    "\n",
    "Them the **normalised betweenness centrality**, $C_i^B$ of node $i$ is\n",
    "$$ C_i^B = \\frac{c_i^B}{(n-1)(n-2)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Before we delve into the algorithms, let's take a simple network to study:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G4 = nx.Graph() \n",
    "G4.add_edges_from(['ab','ac','bd','cd','de','df']) # Example\n",
    "nx.draw(G4,**opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The quantities, particularly, $n_i(j,k)$, can take some work to compute.\n",
    "Yet again, we use a variant on **BFS**.\n",
    "\n",
    "First for any given any node, we need to compute all its **predecessors** on the shortest paths between it and every other node. That is, if `z` is a predecessor of `x` if it is a neighbour `x`, and on the shortest path between `x` and `y`. \n",
    "\n",
    "This is then used to count the _number_ of shortest paths between a pair of nodes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our function works as follows:\n",
    "1. Takes the graph G  and node x as inputs\n",
    "2. Returns a dictionary, `preds` where `preds[y]` is the list of predecessors of x in the paths from y to x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecessors(G, x):\n",
    "    \"\"\" Computes the predecssors of Node x in G\"\"\"\n",
    "    # 1. init: set up the two dictionaries and queue\n",
    "    dists = { y: None for y in G } # distances\n",
    "    preds = { y: [] for y in G } \n",
    "    Q = Queue()\n",
    "    dists[x] = 0 # \n",
    "    Q.put(x)\n",
    "    \n",
    "    # 2. loop\n",
    "    while not Q.empty():\n",
    "        y = Q.get()\n",
    "        for z in G.neighbors(y):\n",
    "            if dists[z] is None:\n",
    "                dists[z] = dists[y] + 1\n",
    "                preds[z].append(y)\n",
    "                Q.put(z)\n",
    "            elif dists[z] > dists[y]:\n",
    "                preds[z].append(y)\n",
    "    \n",
    "    # 3. stop here\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's check it it works by computing all the predecessors of `a`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = predecessors(G4,'a') ## check our work\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Using the **predecessor lists** with respect to $x$, the **shortest paths** from $x$ to $y$ can be enumerated recursively:\n",
    "* if $y = x$: the shortest path from $x$ to itself is the empty path starting and ending at $x$.\n",
    "* else, if $y \\neq x$ then each shortest path from $x$ to $y$ travels through\n",
    "  exactly one of $x$'s predecessors ... and ends in $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_paths(G, x, y):\n",
    "    if x == y:\n",
    "        return [[x]]\n",
    "    paths = []\n",
    "    pred_x_y = predecessors(G, x)[y] # predicessors of x in paths x to y\n",
    "    # print(f\"preds of {y} are {pred_x_y}\")  # uncomment for more info\n",
    "    for z in pred_x_y:\n",
    "        for path in shortest_paths(G, x, z):\n",
    "            paths.append(path + [y])\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_paths(G4, 'a', 'f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally, we can compute the _betweenness_ of a node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def betweeness(G):\n",
    "    CB = { i : 0.0 for i in G }\n",
    "    n = G.order()\n",
    "    for i in G: \n",
    "        for j in G:\n",
    "            for k in G:\n",
    "                paths_jk = shortest_paths(G, j, k)\n",
    "                n_jk = len(paths_jk)\n",
    "                n_i_jk = 0\n",
    "                for p in paths_jk:\n",
    "                    if i in p[1:-1]: # exclude enpoint\n",
    "                        n_i_jk+=1\n",
    "                CB[i] += n_i_jk/n_jk\n",
    "        CB[i] /= ((n-1)*(n-2)) # normalise\n",
    "    return(CB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betweeness(G4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Naturally, this can also be done in `networkx`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.betweenness_centrality(G4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: 15th-century Florentine marriages\n",
    "\n",
    "There is a famous network used to represent the marriage network of sixteen families in Florence, originally developed to showed how the Medici family gained power and took control of Florence by creating a high number of inter-marriages with the other families; see [Wikipedia](https://en.wikipedia.org/wiki/Strategic_network_formation)\n",
    "\n",
    "### The example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFG = nx.florentine_families_graph()\n",
    "print(f\"There are {FFG.order()} nodes and {FFG.size()} links in the network.\")\n",
    "pos = nx.spring_layout(FFG, seed=0) # record for layer use.\n",
    "nx.draw(FFG, **opts, pos=pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Compute centralities \n",
    "Let's compute the centralities of each (using `networkx` methods):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CD = nx.degree_centrality(FFG)\n",
    "CE = nx.eigenvector_centrality(FFG)\n",
    "CC = nx.closeness_centrality(FFG)\n",
    "CB = nx.betweenness_centrality(FFG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's display the results in a `pandas` data frameL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'Key': list(CD.keys()),\n",
    "    'Degree': list(CD.values()),\n",
    "    'Eigenv': list(CE.values()),\n",
    "    'Closen': list(CC.values()),\n",
    "    'Betwee': list(CB.values())\n",
    "}).sort_values('Degree', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Drawing graphs based on centrality\n",
    "We'll finish by plotting the graphs again, but this time using the centralities measures to control the node sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "node_sizes = [CD[node]*6000 for node in FFG.nodes()]\n",
    "nx.draw(FFG, with_labels=True, node_size=node_sizes, node_color='skyblue', pos=pos)\n",
    "plt.title('Degree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "node_sizes = [CE[node] * 6000 for node in FFG.nodes()]\n",
    "nx.draw(FFG, with_labels=True, node_size=node_sizes, node_color='plum', pos=pos)\n",
    "plt.title('Eigevector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "node_sizes = [CC[node]*6000 for node in FFG.nodes()]\n",
    "nx.draw(FFG, with_labels=True, node_size=node_sizes, node_color='yellow', pos=pos)\n",
    "plt.title('Closeness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "node_sizes = [CB[node]*6000 for node in FFG.nodes()]\n",
    "nx.draw(FFG, with_labels=True, node_size=node_sizes, node_color='lime', pos=pos)\n",
    "plt.title('Betweenness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "node_sizes = [CC[node]*6000 for node in FFG.nodes()]\n",
    "node_colors = [CC[node] for node in FFG.nodes()] \n",
    "nx.draw(FFG, with_labels=True, node_size=node_sizes, node_color=node_colors, cmap=plt.cm.cool, font_size=10, pos=pos)\n",
    "plt.title('Closeness (colour and size)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Code corner (not covered in class explicitly)\n",
    "\n",
    "This is a list a list of functions, and coding ideas, used in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How to make a dictionary from two lists: one of keys, one of values, using `zip`. In this case, we'll make one based on the list of nodes, and vector of degree centralities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_vector # Note this is a (6,1) array, not a (6,) array: need to flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CD_dict = dict(zip(range(6), list(degree_vector.flatten() )))\n",
    "print(CD_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">Finished here <b>Thursday</b></div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python (CS4423)",
   "language": "python",
   "name": "cs4423"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
